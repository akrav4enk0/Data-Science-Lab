# Results

This folder contains summary artifacts generated by the benchmarking scripts.

## Files

- `fib_latency_mean.csv`  
  Report table: per-model mean latency (seconds) over **50 measured runs**, excluding **3 warmup runs**.

- `fib_latency_summary.csv`  
  Raw per-run log used to compute the means. Contains one row per measured run with:
  `timestamp, model, task, real_seconds, output_file`.

  Notes:
  - The `output_file` values are **local absolute paths** (machine-specific).
  - Per-run model outputs (`results/answers/*.txt`) are generated locally and are **not tracked** in Git.

- `terminalbench_summary.csv`
  Summary statistics of the benchmark evaluation, including solved trails, unsolved trails, accuracy rates.
  
- `terminal-ben analysis.png`
   Visualization of the `terminalbench_summary.csv`

## How these were produced

Benchmarks were executed via:

```bash
CLEAR_RESULTS=1 MODELS="modelA,modelB" ./scripts/bench_loop_fib.sh "" fib 50 3
