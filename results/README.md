# Results

This folder contains summary artifacts generated by the benchmarking scripts.

## Files
- [/terminal-bench results](https://github.com/akrav4enk0/Data-Science-Lab/tree/main/results/terminal-bench)  

  This folder contains:
- `fib_latency_mean.csv`  
  Report table: per-model mean latency (seconds) over **50 measured runs**, excluding **3 warmup runs**.

- `fib_latency_summary.csv`  
  Raw per-run log used to compute the means. Contains one row per measured run with:
  `timestamp, model, task, real_seconds, output_file`.

- results/terminal-bench/runs_json (https://github.com/akrav4enk0/Data-Science-Lab/tree/main/results/terminal-bench/runs_json) consists of all Terminal-Bench JSON result records.
  Notes:
  - The `output_file` values are **local absolute paths** (machine-specific).
  - Per-run model outputs (`results/answers/*.txt`) are generated locally and are **not tracked** in Git.

- `terminalbench_summary.csv`

  Summary statistics of the benchmark evaluation, including solved trails, unsolved trails, accuracy rates.
  
- `terminal-ben analysis.png`

- Visualization of the `terminalbench_summary.csv` shown as `plot_terminalbench_results.py`. The code is in [scripts/plot_terminalbench_results.py](https://github.com/akrav4enk0/Data-Science-Lab/blob/main/scripts/plot_terminalbench_results.py)

## How these were produced

Benchmarks were executed via:

```bash
CLEAR_RESULTS=1 MODELS="modelA,modelB" ./scripts/bench_loop_fib.sh "" fib 50 3
