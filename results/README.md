# Results

This folder contains summary artifacts generated by the benchmarking scripts.

## Folder [/terminal-bench results](https://github.com/akrav4enk0/Data-Science-Lab/tree/main/results/terminal-bench)  

This folder contains:
- [`terminal-bench_summary.csv`](https://github.com/akrav4enk0/Data-Science-Lab/blob/main/results/terminal-bench/terminal-bench_summary.csv) - summary statistics of the benchmark evaluation, including solved trails, unsolved trails, accuracy rates.
  
- [`terminal-bench_analysis.png`](https://github.com/akrav4enk0/Data-Science-Lab/blob/main/results/terminal-bench/terminal-bench_analysis.png) - visualization of the [`terminal-bench_summary.csv`](https://github.com/akrav4enk0/Data-Science-Lab/blob/main/results/terminal-bench/terminal-bench_summary.csv) shown as [`plot_terminalbench_results.py`](https://github.com/akrav4enk0/Data-Science-Lab/tree/main/scripts/terminal-bench). 
  
- [/runs_json](https://github.com/akrav4enk0/Data-Science-Lab/tree/main/results/terminal-bench/runs_json) folder, that contains all Terminal-Bench JSON result records, for example [`Apertus-70B-results.json`](https://github.com/akrav4enk0/Data-Science-Lab/blob/main/results/terminal-bench/runs_json/Apertus-70B-results.json)

## Folder [/fib_latency_benchmark](https://github.com/akrav4enk0/Data-Science-Lab/tree/main/results/fib_latency_benchmark)

This folder contains:
- [`fib_latency_mean.csv`](https://github.com/akrav4enk0/Data-Science-Lab/blob/main/results/fib_latency_benchmark/fib_latency_mean.csv) - report table: per-model mean latency (seconds) over 50 measured runs, excluding 3 warmup runs.

- [`fib_latency_summary.csv`](https://github.com/akrav4enk0/Data-Science-Lab/blob/main/results/fib_latency_benchmark/fib_latency_summary.csv) - raw per-run log used to compute the means. Contains one row per measured run with: `timestamp, model, task, real_seconds, output_file`.

- [/sample_outputs](https://github.com/akrav4enk0/Data-Science-Lab/tree/main/results/fib_latency_benchmark/sample_outputs) folder, that contains a few examples of model outputs from the Fibonacci latency benchmark (based on custom script), committed as evidence of actual runs, such as [`swiss-ai_Apertus-70B-Instruct-2509_fib_20251221_013332.txt`](https://github.com/akrav4enk0/Data-Science-Lab/blob/main/results/fib_latency_benchmark/sample_outputs/swiss-ai_Apertus-70B-Instruct-2509_fib_20251221_013332.txt)
Full per-run outputs are generated locally (one file per run) and are not fully tracked in Git to keep the repository lightweight.


## Reproducing the results

- Terminal-Bench runs: see [`docs/terminal-bench-guide.md`](https://github.com/akrav4enk0/Data-Science-Lab/blob/main/docs/terminal-bench-guide.md)
- Fibonacci latency benchmark: see [`docs/fib-latency-benchmark-guide.md`](https://github.com/akrav4enk0/Data-Science-Lab/blob/main/docs/fib-latency-benchmark-guide.md)

